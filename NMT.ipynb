{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOvRVlZ0n7Ofyf/HLNT1T3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shantanu812/MLProjects/blob/main/NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fBGSXy_ai8Yt"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "if IS_COLAB:\n",
        "    import os\n",
        "    os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "    import tf_keras"
      ],
      "metadata": {
        "id": "JQwZTl-cnkhh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ],
      "metadata": {
        "id": "gsATvKSxnoP2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
        "              \"accelerator.\")\n",
        "    if \"kaggle_secrets\" in sys.modules:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")"
      ],
      "metadata": {
        "id": "E-mg0V-xnvKX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "LlKpmW8CoY3d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "path=tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\",extract=True)\n",
        "text = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text()"
      ],
      "metadata": {
        "id": "vR4IwWy0nwbC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs)"
      ],
      "metadata": {
        "id": "udU2DWuKod1z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(sentences_en[i], \"=>\", sentences_es[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOFjF8OEqDKw",
        "outputId": "44906779-c4c8-430e-bb52-989bd3da7012"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How boring! => Qué aburrimiento!\n",
            "I love sports. => Adoro el deporte.\n",
            "Would you like to swap jobs? => Te gustaría que intercambiemos los trabajos?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=1000\n",
        "max_length=50\n",
        "text_vec_layer_en=tf.keras.layers.TextVectorization(max_tokens=vocab_size,output_sequence_length=max_length)\n",
        "text_vec_layer_es=tf.keras.layers.TextVectorization(max_tokens=vocab_size,output_sequence_length=max_length)\n",
        "text_vec_layer_en.adapt(sentences_en)\n",
        "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])"
      ],
      "metadata": {
        "id": "XpH2KPypqFtR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer_en.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEjhiUgGsPex",
        "outputId": "f6452e1a-627e-4187-b724-d00842d416ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('the'),\n",
              " np.str_('i'),\n",
              " np.str_('to'),\n",
              " np.str_('you'),\n",
              " np.str_('tom'),\n",
              " np.str_('a'),\n",
              " np.str_('is'),\n",
              " np.str_('he')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer_es.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH0dDyu6sZGL",
        "outputId": "96af5016-b303-48b1-a2e9-05669e0071f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('startofseq'),\n",
              " np.str_('endofseq'),\n",
              " np.str_('de'),\n",
              " np.str_('que'),\n",
              " np.str_('a'),\n",
              " np.str_('no'),\n",
              " np.str_('tom'),\n",
              " np.str_('la')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.constant(sentences_en[:100_000])\n",
        "X_valid = tf.constant(sentences_en[100_000:])\n",
        "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
        "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
        "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
        "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])"
      ],
      "metadata": {
        "id": "44sW6EPHsivl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = tf.keras.layers.Input(shape=[],dtype=tf.string)\n",
        "decoder_inputs = tf.keras.layers.Input(shape=[],dtype=tf.string)"
      ],
      "metadata": {
        "id": "pL2xDE50tXe4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size=128\n",
        "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
        "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
        "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=True)\n",
        "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
        "                                                    mask_zero=True)\n",
        "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
      ],
      "metadata": {
        "id": "RVUrNddbvPGz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)"
      ],
      "metadata": {
        "id": "GTqspzXiv4ym"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
      ],
      "metadata": {
        "id": "pw7PKwfIwipv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "Y_proba = output_layer(decoder_outputs)"
      ],
      "metadata": {
        "id": "wc2V2L-pwkJP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                       outputs=[Y_proba])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Nl9xGuwqdN",
        "outputId": "40eb0380-2886-4179-a776-f2f39fce0000"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3125/3125 [==============================] - 89s 25ms/step - loss: 2.9501 - accuracy: 0.4224 - val_loss: 2.2190 - val_accuracy: 0.5163\n",
            "Epoch 2/10\n",
            "3125/3125 [==============================] - 59s 19ms/step - loss: 1.8810 - accuracy: 0.5698 - val_loss: 1.6664 - val_accuracy: 0.6096\n",
            "Epoch 3/10\n",
            "3125/3125 [==============================] - 58s 19ms/step - loss: 1.4484 - accuracy: 0.6465 - val_loss: 1.4346 - val_accuracy: 0.6510\n",
            "Epoch 4/10\n",
            "3125/3125 [==============================] - 60s 19ms/step - loss: 1.2072 - accuracy: 0.6937 - val_loss: 1.3262 - val_accuracy: 0.6745\n",
            "Epoch 5/10\n",
            "3125/3125 [==============================] - 58s 19ms/step - loss: 1.0410 - accuracy: 0.7276 - val_loss: 1.2849 - val_accuracy: 0.6819\n",
            "Epoch 6/10\n",
            "3125/3125 [==============================] - 60s 19ms/step - loss: 0.9066 - accuracy: 0.7563 - val_loss: 1.2800 - val_accuracy: 0.6865\n",
            "Epoch 7/10\n",
            "3125/3125 [==============================] - 59s 19ms/step - loss: 0.7903 - accuracy: 0.7822 - val_loss: 1.2939 - val_accuracy: 0.6859\n",
            "Epoch 8/10\n",
            "3125/3125 [==============================] - 58s 19ms/step - loss: 0.6901 - accuracy: 0.8053 - val_loss: 1.3270 - val_accuracy: 0.6858\n",
            "Epoch 9/10\n",
            "3125/3125 [==============================] - 57s 18ms/step - loss: 0.6027 - accuracy: 0.8266 - val_loss: 1.3653 - val_accuracy: 0.6809\n",
            "Epoch 10/10\n",
            "3125/3125 [==============================] - 58s 19ms/step - loss: 0.5275 - accuracy: 0.8459 - val_loss: 1.4141 - val_accuracy: 0.6808\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x79bc5e024110>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence_en):\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = np.array([sentence_en])  # encoder input\n",
        "        X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
        "        y_proba = model.predict((X, X_dec))[0, word_idx]  # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "    return translation.strip()"
      ],
      "metadata": {
        "id": "VTxfbc170C1M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"I like to eat pizza\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "UYUBHR_j0IMy",
        "outputId": "1fc2a824-4fb0-4346-85bc-cd83a36e12e6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gusta comer [UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"Have you ever done this\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "5X0zVXOd0kpo",
        "outputId": "88d8a07f-1006-482b-d32d-7b4a665442ab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'has hecho esto alguna cosa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "encoder = tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.LSTM(256, return_state=True))"
      ],
      "metadata": {
        "id": "iw8ys2Q22jYY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
        "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
        "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)"
      ],
      "metadata": {
        "id": "s6RQt2_B2tkO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n",
        "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "Y_proba = output_layer(decoder_outputs)\n",
        "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                       outputs=[Y_proba])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPx-H2U12vgy",
        "outputId": "1ff8c807-9d1f-4c84-c198-25811aa0fe20"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3125/3125 [==============================] - 111s 31ms/step - loss: 2.0636 - accuracy: 0.5561 - val_loss: 1.4676 - val_accuracy: 0.6467\n",
            "Epoch 2/10\n",
            "3125/3125 [==============================] - 74s 24ms/step - loss: 1.2798 - accuracy: 0.6817 - val_loss: 1.2753 - val_accuracy: 0.6809\n",
            "Epoch 3/10\n",
            "3125/3125 [==============================] - 72s 23ms/step - loss: 1.0676 - accuracy: 0.7234 - val_loss: 1.2023 - val_accuracy: 0.6986\n",
            "Epoch 4/10\n",
            "3125/3125 [==============================] - 73s 24ms/step - loss: 0.9219 - accuracy: 0.7541 - val_loss: 1.1793 - val_accuracy: 0.7023\n",
            "Epoch 5/10\n",
            "3125/3125 [==============================] - 73s 24ms/step - loss: 0.8026 - accuracy: 0.7797 - val_loss: 1.1836 - val_accuracy: 0.7063\n",
            "Epoch 6/10\n",
            "3125/3125 [==============================] - 75s 24ms/step - loss: 0.7012 - accuracy: 0.8028 - val_loss: 1.2066 - val_accuracy: 0.7021\n",
            "Epoch 7/10\n",
            "3125/3125 [==============================] - 76s 24ms/step - loss: 0.6141 - accuracy: 0.8237 - val_loss: 1.2446 - val_accuracy: 0.7027\n",
            "Epoch 8/10\n",
            "3125/3125 [==============================] - 78s 25ms/step - loss: 0.5377 - accuracy: 0.8424 - val_loss: 1.2873 - val_accuracy: 0.7004\n",
            "Epoch 9/10\n",
            "3125/3125 [==============================] - 80s 26ms/step - loss: 0.4760 - accuracy: 0.8581 - val_loss: 1.3386 - val_accuracy: 0.6970\n",
            "Epoch 10/10\n",
            "3125/3125 [==============================] - 77s 25ms/step - loss: 0.4250 - accuracy: 0.8718 - val_loss: 1.3830 - val_accuracy: 0.6938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x79bc627f2910>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"I like soccer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "1lYhK-Pr6HVI",
        "outputId": "13d181e8-bcbd-44a7-d138-a701201c04f2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gusta el fútbol'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search(sentence_en, beam_width, verbose=False):\n",
        "    X = np.array([sentence_en])  # encoder input\n",
        "    X_dec = np.array([\"startofseq\"])  # decoder input\n",
        "    y_proba = model.predict((X, X_dec))[0, 0]  # first token's probas\n",
        "    top_k = tf.math.top_k(y_proba, k=beam_width)\n",
        "    top_translations = [  # list of best (log_proba, translation)\n",
        "        (np.log(word_proba), text_vec_layer_es.get_vocabulary()[word_id])\n",
        "        for word_proba, word_id in zip(top_k.values, top_k.indices)\n",
        "    ]\n",
        "\n",
        "    # extra code – displays the top first words in verbose mode\n",
        "    if verbose:\n",
        "        print(\"Top first words:\", top_translations)\n",
        "\n",
        "    for idx in range(1, max_length):\n",
        "        candidates = []\n",
        "        for log_proba, translation in top_translations:\n",
        "            if translation.endswith(\"endofseq\"):\n",
        "                candidates.append((log_proba, translation))\n",
        "                continue  # translation is finished, so don't try to extend it\n",
        "            X = np.array([sentence_en])  # encoder input\n",
        "            X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
        "            y_proba = model.predict((X, X_dec))[0, idx]  # last token's proba\n",
        "            for word_id, word_proba in enumerate(y_proba):\n",
        "                word = text_vec_layer_es.get_vocabulary()[word_id]\n",
        "                candidates.append((log_proba + np.log(word_proba),\n",
        "                                   f\"{translation} {word}\"))\n",
        "        top_translations = sorted(candidates, reverse=True)[:beam_width]\n",
        "\n",
        "        # extra code – displays the top translation so far in verbose mode\n",
        "        if verbose:\n",
        "            print(\"Top translations so far:\", top_translations)\n",
        "\n",
        "        if all([tr.endswith(\"endofseq\") for _, tr in top_translations]):\n",
        "            return top_translations[0][1].replace(\"endofseq\", \"\").strip()"
      ],
      "metadata": {
        "id": "OyGuYb6x7HGS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_en = \"I love cats and dogs\"\n",
        "beam_search(sentence_en, beam_width=3, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "Eo2Dchp67JyS",
        "outputId": "09a595c6-fef5-4294-a2a7-7c0ce138f8d8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 88ms/step\n",
            "Top first words: [(np.float32(-0.00048231788), np.str_('me')), (np.float32(-8.851679), np.str_('odio')), (np.float32(-9.0113535), np.str_('yo'))]\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Top translations so far: [(np.float32(-0.44103795), 'me encanta'), (np.float32(-1.3827684), 'me [UNK]'), (np.float32(-2.3593988), 'me gustan')]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Top translations so far: [(np.float32(-1.4603), 'me encanta los'), (np.float32(-1.7360574), 'me [UNK] y'), (np.float32(-2.2112076), 'me encanta el')]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Top translations so far: [(np.float32(-1.7452489), 'me [UNK] y los'), (np.float32(-2.0263782), 'me encanta los perros'), (np.float32(-2.3117213), 'me encanta los gatos')]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Top translations so far: [(np.float32(-1.7596743), 'me [UNK] y los perros'), (np.float32(-2.108247), 'me encanta los perros y'), (np.float32(-2.3124673), 'me encanta los gatos y')]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Top translations so far: [(np.float32(-2.2503185), 'me [UNK] y los perros son'), (np.float32(-2.3658452), 'me encanta los gatos y perros'), (np.float32(-2.68583), 'me encanta los perros y los')]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Top translations so far: [(np.float32(-2.3665447), 'me encanta los gatos y perros endofseq'), (np.float32(-2.713923), 'me encanta los perros y los gatos'), (np.float32(-2.8675218), 'me [UNK] y los perros son [UNK]')]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Top translations so far: [(np.float32(-2.3665447), 'me encanta los gatos y perros endofseq'), (np.float32(-2.7140698), 'me encanta los perros y los gatos endofseq'), (np.float32(-2.867774), 'me [UNK] y los perros son [UNK] endofseq')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me encanta los gatos y perros'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_translation_model.keras\")"
      ],
      "metadata": {
        "id": "1xI1QI2C7ryM"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}